{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we are going to investigate the cached_escape function in cached_semantics.py to reproduce the AUC result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.75\n"
     ]
    }
   ],
   "source": [
    "# 0. look up auc function in sklearn\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "# Example data (FPR, TPR)\n",
    "fpr = np.array([0.0, 0.1, 0.2, 0.3, 0.4, 1.0])\n",
    "tpr = np.array([0.0, 0.4, 0.6, 0.7, 0.8, 1.0])\n",
    "\n",
    "# Calculate AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "# I finded out this function simply gets the area under the curve of the ROC curve described by the fpr and tpr arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>wt</th>\n",
       "      <th>mut</th>\n",
       "      <th>prob</th>\n",
       "      <th>change</th>\n",
       "      <th>is_viable</th>\n",
       "      <th>is_escape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pos, wt, mut, prob, change, is_viable, is_escape]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "cov_cscs_path = \"../results/cov/semantics/analyze_semantics_cov_bilstm_512.txt\"\n",
    "# ignore U B J X Z\n",
    "rbd_cscs_path = \"../results/cov/semantics/analyze_semantics_cov2rbd_bilstm_512.txt\"\n",
    "cov_df = pd.read_csv(cov_cscs_path, sep=\"\\t\")\n",
    "# cov_df = cov_df[(cov_df[\"wt\"] != \"U\") & (cov_df[\"wt\"] != \"B\") & \n",
    "#               (cov_df[\"wt\"] != \"J\") & (cov_df[\"wt\"] != \"X\") & (cov_df[\"wt\"] != \"Z\")]\n",
    "\n",
    "df = cov_df[cov_df['wt'] == 'Z']\n",
    "df\n",
    "# print(cov_df)\n",
    "# len(cov_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8659576887100414, 0.8390053866706172, 0.6598051358553816)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. before start test the main function in cached_semantics.py first\n",
    "def get_aucs(df: pd.DataFrame):\n",
    "    \"\"\"What we need is sars-cov-2 related results, so we ignore codes not related \n",
    "    to sars-cov-2.\n",
    "    wt_seq & seqs_escape are used to calculate AUC.\n",
    "    \"\"\"\n",
    "    \"\"\"get prob & orig_prob from table\n",
    "    escape_rank_dist, escape_idx\n",
    "    acquisition = CSCS score (rank base)\n",
    "     = apply rank to the array(grammar and semantic change) and sum\n",
    "\n",
    "    target values: norm_auc, norm_auc_prob, norm_auc_change\n",
    "\n",
    "    for RBD, ignore pos < 330 or pos > 530\n",
    "    \"\"\"\n",
    "    grammaticalities = df['prob']\n",
    "    semantic_changes = df['change']\n",
    "\n",
    "    gram_ranks = grammaticalities.rank(ascending=False)\n",
    "    sem_ranks = semantic_changes.rank(ascending=False)\n",
    "\n",
    "    escape_indices = df[df['is_escape'] == True].index\n",
    "    # acquisition = cscs_scores\n",
    "    cscs_scores = gram_ranks + sem_ranks\n",
    "    len_probs = len(grammaticalities)\n",
    "    num_to_consider = list(range(1, len(grammaticalities) + 1))\n",
    "    # escape mutants rank of cscs score\n",
    "    escape_ranks_cscs = cscs_scores.rank()[escape_indices]\n",
    "    escape_ranks_gram = gram_ranks[escape_indices]\n",
    "    escape_ranks_sem = sem_ranks[escape_indices]\n",
    "    n_escape_cscs = [sum(escape_ranks_cscs <= i + 1) for i in range(len_probs)]\n",
    "    n_escape_gram = [sum(escape_ranks_gram <= i + 1) for i in range(len_probs)]\n",
    "    n_escape_sem = [sum(escape_ranks_sem <= i + 1) for i in range(len_probs)]\n",
    "\n",
    "    norm = (len_probs + 1) * len(escape_ranks_cscs)\n",
    "\n",
    "    # auc of cscs\n",
    "    norm_auc_cscs = auc(num_to_consider, n_escape_cscs) / norm\n",
    "    # auc of grammaticalities\n",
    "    norm_auc_gram = auc(num_to_consider, n_escape_gram) / norm\n",
    "    # auc of semantic change \n",
    "    norm_auc_sem = auc(num_to_consider, n_escape_sem) / norm\n",
    "    \n",
    "    return (norm_auc_cscs, norm_auc_gram, norm_auc_sem)\n",
    "result = get_aucs(cov_df)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of escape seqs: 19 / 19\n",
      "Mean rank: 3757.657894736842 / 24187\n",
      "Median rank: 3700.0 / 24187\n",
      "Min rank: 122.0 / 24187\n",
      "Max rank: 7815.0 / 24187\n",
      "Rank stdev: 2574.3142267849016 / 24187\n",
      "AUC (CSCS): 0.8446610075442876, P = 0.0\n",
      "AUC (semantic change only): 0.6364478090666364\n",
      "AUC (grammaticality only): 0.7966774234963105\n",
      "-6.262 (mean log prob), -4.557 (mean log prob escape), 7.539e-06 (p-value)\n",
      "3717 (mean log change), 3958 (mean log change escape), 0.03944 (p-value)\n"
     ]
    }
   ],
   "source": [
    "def cached_escape_original(cache_fname):\n",
    "    from escape import load_baum2020\n",
    "    wt_seq, seqs_escape = load_baum2020('../data/cov/cov2_spike_wt.fasta')\n",
    "    prob, change, escape_idx, viable_idx = [], [], [], []\n",
    "    with open(cache_fname) as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            fields = line.rstrip().split(\"\\t\")\n",
    "            pos = int(fields[0])\n",
    "            if \"rbd\" in cache_fname:\n",
    "                if pos < 330 or pos > 530:\n",
    "                    continue\n",
    "            if fields[2] in {\"U\", \"B\", \"J\", \"X\", \"Z\"}:\n",
    "                continue\n",
    "            aa_wt = fields[1]\n",
    "            aa_mut = fields[2]\n",
    "            assert wt_seq[pos] == aa_wt\n",
    "            mut_seq = wt_seq[:pos] + aa_mut + wt_seq[pos + 1 :]\n",
    "            if mut_seq not in seqs_escape:\n",
    "                continue\n",
    "            prob.append(float(fields[3]))\n",
    "            change.append(float(fields[4]))\n",
    "            viable_idx.append(fields[5] == \"True\")\n",
    "            escape_idx.append(\n",
    "                (mut_seq in seqs_escape)\n",
    "                and (sum([m[\"significant\"] for m in seqs_escape[mut_seq]]) > 0)\n",
    "            )\n",
    "\n",
    "    prob, orig_prob = np.array(prob), np.array(prob)\n",
    "    change, orig_change = np.array(change), np.array(change)\n",
    "    escape_idx = np.array(escape_idx)\n",
    "    viable_idx = np.array(viable_idx)\n",
    "\n",
    "    beta = 1.0\n",
    "    acquisition = ss.rankdata(change) + (beta * ss.rankdata(prob))\n",
    "\n",
    "    pos_change_idx = change > 0\n",
    "\n",
    "    pos_change_escape_idx = np.logical_and(pos_change_idx, escape_idx)\n",
    "    escape_prob = prob[pos_change_escape_idx]\n",
    "    escape_change = change[pos_change_escape_idx]\n",
    "    prob = prob[pos_change_idx]\n",
    "    change = change[pos_change_idx]\n",
    "\n",
    "    log_prob, log_change = np.log10(prob), np.log10(change)\n",
    "    log_escape_prob, log_escape_change = (\n",
    "        np.log10(escape_prob),\n",
    "        np.log10(escape_change),\n",
    "    )\n",
    "\n",
    "    acq_argsort = ss.rankdata(-acquisition)\n",
    "    escape_rank_dist = acq_argsort[escape_idx]\n",
    "\n",
    "    size = len(prob)\n",
    "    print(\n",
    "        \"Number of escape seqs: {} / {}\".format(len(escape_rank_dist), sum(escape_idx))\n",
    "    )\n",
    "    print(\"Mean rank: {} / {}\".format(np.mean(escape_rank_dist), size))\n",
    "    print(\"Median rank: {} / {}\".format(np.median(escape_rank_dist), size))\n",
    "    print(\"Min rank: {} / {}\".format(np.min(escape_rank_dist), size))\n",
    "    print(\"Max rank: {} / {}\".format(np.max(escape_rank_dist), size))\n",
    "    print(\"Rank stdev: {} / {}\".format(np.std(escape_rank_dist), size))\n",
    "\n",
    "    max_consider = len(prob)\n",
    "    n_consider = np.array([i + 1 for i in range(max_consider)])\n",
    "\n",
    "    n_escape = np.array([sum(escape_rank_dist <= i + 1) for i in range(max_consider)])\n",
    "    norm = max(n_consider) * max(n_escape)\n",
    "    norm_auc = auc(n_consider, n_escape) / norm\n",
    "\n",
    "    escape_rank_prob = ss.rankdata(-orig_prob)[escape_idx]\n",
    "    n_escape_prob = np.array(\n",
    "        [sum(escape_rank_prob <= i + 1) for i in range(max_consider)]\n",
    "    )\n",
    "    norm_auc_prob = auc(n_consider, n_escape_prob) / norm\n",
    "\n",
    "    escape_rank_change = ss.rankdata(-orig_change)[escape_idx]\n",
    "    n_escape_change = np.array(\n",
    "        [sum(escape_rank_change <= i + 1) for i in range(max_consider)]\n",
    "    )\n",
    "    norm_auc_change = auc(n_consider, n_escape_change) / norm\n",
    "\n",
    "    def compute_p(true_val, n_interest, n_total, n_permutations=10000):\n",
    "        null_distribution = []\n",
    "        norm = n_interest * n_total\n",
    "        for _ in range(n_permutations):\n",
    "            interest = set(np.random.choice(n_total, size=n_interest, replace=False))\n",
    "            n_acquired = 0\n",
    "            acquired, total = [], []\n",
    "            for i in range(n_total):\n",
    "                if i in interest:\n",
    "                    n_acquired += 1\n",
    "                acquired.append(n_acquired)\n",
    "                total.append(i + 1)\n",
    "            null_distribution.append(auc(total, acquired) / norm)\n",
    "        null_distribution = np.array(null_distribution)\n",
    "        return sum(null_distribution >= true_val) / n_permutations\n",
    "\n",
    "    norm_auc_p = compute_p(norm_auc, sum(escape_idx), len(escape_idx))\n",
    "\n",
    "    print(\"AUC (CSCS): {}, P = {}\".format(norm_auc, norm_auc_p))\n",
    "    print(\"AUC (semantic change only): {}\".format(norm_auc_change))\n",
    "    print(\"AUC (grammaticality only): {}\".format(norm_auc_prob))\n",
    "\n",
    "    print(\n",
    "        \"{:.4g} (mean log prob), {:.4g} (mean log prob escape), \"\n",
    "        \"{:.4g} (p-value)\".format(\n",
    "            log_prob.mean(),\n",
    "            log_escape_prob.mean(),\n",
    "            ss.mannwhitneyu(log_prob, log_escape_prob, alternative=\"two-sided\")[1],\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"{:.4g} (mean log change), {:.4g} (mean log change escape), \"\n",
    "        \"{:.4g} (p-value)\".format(\n",
    "            change.mean(),\n",
    "            escape_change.mean(),\n",
    "            ss.mannwhitneyu(change, escape_change, alternative=\"two-sided\")[1],\n",
    "        )\n",
    "    )\n",
    "result = cached_escape_original(cov_cscs_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-mut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
